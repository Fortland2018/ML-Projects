{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 34377,
          "databundleVersionId": 3220602,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31089,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "spaceTitanicByZ",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fortland2018/ML-Projects/blob/main/SpaceTitanic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "PMr7SQ_9u5P0"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "spaceship_titanic_path = kagglehub.competition_download('spaceship-titanic')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "gLCa7uNdu5P2"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Wczytaj dane\n",
        "train = pd.read_csv('/kaggle/input/spaceship-titanic/train.csv')\n",
        "test = pd.read_csv('/kaggle/input/spaceship-titanic/test.csv')\n",
        "\n",
        "\n",
        "\n",
        "# %%\n",
        "#CRYOSLEEP\n",
        "\n",
        "\n",
        "def map_cryo(val):\n",
        "    if pd.isna(val):\n",
        "        return 0.5\n",
        "    if val in [True, 'True', 1, '1']:\n",
        "        return 1\n",
        "    if val in [False, 'False', 0, '0']:\n",
        "        return 0\n",
        "    return 0.5  # na wszelki wypadek\n",
        "\n",
        "train['CryoSleep'] = train['CryoSleep'].apply(map_cryo).astype('float64')\n",
        "test['CryoSleep'] = test['CryoSleep'].apply(map_cryo).astype('float64')\n",
        "\n",
        "# %%\n",
        "\n",
        "# Połącz zbiory\n",
        "train['is_train'] = 1\n",
        "test['is_train'] = 0\n",
        "full = pd.concat([train, test], ignore_index=True)\n",
        "\n",
        "# Kodowanie kategorii na pełnym zbiorze\n",
        "for col in ['HomePlanet', 'Cabin', 'Destination', 'VIP']:\n",
        "    full[col] = full[col].astype('category').cat.codes\n",
        "\n",
        "# Rozdziel z powrotem\n",
        "train = full[full['is_train'] == 1].drop(columns=['is_train'])\n",
        "test = full[full['is_train'] == 0].drop(columns=['is_train'])\n",
        "\n",
        "\n",
        "\n",
        "# %%\n",
        "\n",
        "# Uzupełnij brakujące wartości\n",
        "# Impute missing values\n",
        "skip_cols = ['CryoSleep', 'PassengerId']\n",
        "for col in train.columns:\n",
        "    if col in skip_cols:\n",
        "        continue\n",
        "    if train[col].dtype in ['float64', 'int64']:\n",
        "        train[col] = train[col].fillna(train[col].mean())\n",
        "    else:\n",
        "        train[col] = train[col].fillna(train[col].mode()[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(train.loc[train['PassengerId'] == '0064_02', 'HomePlanet'])\n",
        "print(train['CryoSleep'])\n",
        "\n",
        "# %%\n",
        "\n",
        "for col in test.columns:\n",
        "    if test[col].dtype in ['float64', 'int64']:\n",
        "        test[col] = test[col].fillna(test[col].mean())\n",
        "    else:\n",
        "        mode_val = test[col].mode()\n",
        "        if not mode_val.empty:\n",
        "            test[col] = test[col].fillna(mode_val[0])\n",
        "\n",
        "\n",
        "\n",
        "# %%\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Split PassengerId into two features\n",
        "def split_passenger_id(df):\n",
        "    ids = df['PassengerId'].str.split('_', expand=True)\n",
        "    df['Group'] = ids[0].astype(int)\n",
        "    df['Position'] = ids[1].astype(int)\n",
        "    return df\n",
        "print(train['PassengerId'])\n",
        "# Apply to train and test\n",
        "train = split_passenger_id(train)\n",
        "test = split_passenger_id(test)\n",
        "\n",
        "\n",
        "\n",
        "print(train)\n",
        "\n",
        "# %%\n",
        "# Grupowanie po 'Group' i liczenie sumy Transported oraz liczby osób w grupie\n",
        "group_stats = train.groupby('Group')['Transported'].agg(['sum', 'count'])\n",
        "\n",
        "# Dodaj kolumnę: ile osób przeżyło w grupie\n",
        "group_stats['survived'] = group_stats['sum']\n",
        "group_stats['total'] = group_stats['count']\n",
        "\n",
        "\n",
        "# %%\n",
        "# Utwórz słownik: Group -> status (0: wszyscy zginęli, 0.5: mieszana, 1: wszyscy przeżyli)\n",
        "group_status = {}\n",
        "for group, row in group_stats.iterrows():\n",
        "    if row['survived'] == 0:\n",
        "        group_status[group] = 0\n",
        "    elif row['survived'] == row['total']:\n",
        "        group_status[group] = 1\n",
        "    else:\n",
        "        group_status[group] = 0.5\n",
        "print(group_status)\n",
        "print(group_stats)\n",
        "# Dodaj kolumnę do train\n",
        "train['group_survival_status'] = train['Group'].map(group_status)\n",
        "\n",
        "# Dla testu: mogą być grupy, których nie było w train, więc domyślnie 0.5 (nieznany status)\n",
        "test['group_survival_status'] = test['Group'].map(group_status).fillna(0.5)\n",
        "\n",
        "# %%\n",
        "print(train)\n",
        "\n",
        "# %%\n",
        "print(train[['HomePlanet', 'group_survival_status', 'CryoSleep', 'Cabin', 'Destination', 'Age', 'VIP', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']])\n",
        "\n",
        "# %%\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "cols_to_normalize = ['Age', 'Cabin', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
        "\n",
        "# Normalize in train\n",
        "train[cols_to_normalize] = scaler.fit_transform(train[cols_to_normalize])\n",
        "\n",
        "# Normalize in test using train scaler\n",
        "test[cols_to_normalize] = scaler.transform(test[cols_to_normalize])\n",
        "\n",
        "# %%\n",
        "# Wybierz cechy i etykietę\n",
        "features = ['HomePlanet', 'group_survival_status', 'CryoSleep', 'Cabin', 'Destination', 'Age', 'VIP', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck',]\n",
        "X_train = train[features]\n",
        "y_train = train['Transported'].astype(int)\n",
        "X_test = test[features]\n",
        "\n",
        "# Model\n",
        "model = keras.Sequential([\n",
        "    layers.Input(shape=(len(features),)),\n",
        "    layers.Dense(32, activation='relu',),\n",
        "    layers.Dense(16, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Early stopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Trening\n",
        "history = model.fit(X_train, y_train, epochs=12, batch_size=64, validation_split=0.2, verbose=1, callbacks=[early_stop])\n",
        "\n",
        "\n",
        "\n",
        "# %%\n",
        "\n",
        "# Wykres przebiegu uczenia\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.history['loss'], label='Loss')\n",
        "plt.xlabel('Epoka')\n",
        "plt.ylabel('Strata')\n",
        "plt.title('Przebieg straty (loss)')\n",
        "plt.legend()\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history['accuracy'], label='Accuracy', color='green')\n",
        "plt.xlabel('Epoka')\n",
        "plt.ylabel('Dokładność')\n",
        "plt.title('acc')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Histogram wieku pasażerów\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.hist(train['Age'], bins=30, color='skyblue', edgecolor='black')\n",
        "plt.xlabel('Wiek')\n",
        "plt.ylabel('Liczba pasażerów')\n",
        "plt.title('Rozkład wieku pasażerów')\n",
        "plt.show()\n",
        "\n",
        "# Wykres słupkowy liczby pasażerów z podziałem na planety\n",
        "plt.figure(figsize=(6,4))\n",
        "train['HomePlanet'].value_counts().plot(kind='bar', color='orange')\n",
        "plt.xlabel('Planeta')\n",
        "plt.ylabel('Liczba pasażerów')\n",
        "plt.title('Liczba pasażerów z podziałem na planety')\n",
        "plt.show()\n",
        "\n",
        "# Predykcja\n",
        "preds = model.predict(X_test)\n",
        "preds = (preds > 0.5).astype(bool)\n",
        "\n",
        "# Przygotowanie submission\n",
        "submission = pd.DataFrame({\n",
        "    'PassengerId': test['PassengerId'],\n",
        "    'Transported': preds.flatten()\n",
        "})\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-25T23:32:54.389315Z",
          "iopub.execute_input": "2025-07-25T23:32:54.389701Z",
          "iopub.status.idle": "2025-07-25T23:33:02.073876Z",
          "shell.execute_reply.started": "2025-07-25T23:32:54.389673Z",
          "shell.execute_reply": "2025-07-25T23:33:02.072959Z"
        },
        "id": "nVYIEiIqu5P3"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}